{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# If required, create a face detection pipeline using MTCNN:\n",
    "mtcnn = MTCNN(image_size=120, margin= 0)\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: tensor([[-0.0156,  0.0222,  0.0429,  0.0183,  0.0021,  0.0234,  0.0381, -0.0266,\n",
      "         -0.0063, -0.0518,  0.0146, -0.0407, -0.0485,  0.0242,  0.0630, -0.0053,\n",
      "         -0.0352,  0.0495,  0.0490, -0.0129, -0.0302, -0.0552, -0.0050,  0.0046,\n",
      "          0.0203, -0.1405,  0.0098,  0.0471, -0.0569, -0.0062,  0.0185, -0.0314,\n",
      "          0.0452,  0.0433,  0.0326, -0.0211,  0.0443,  0.1151,  0.0495, -0.0592,\n",
      "          0.0397, -0.0163,  0.0117, -0.0214,  0.0715, -0.0084, -0.0519, -0.0670,\n",
      "          0.0266,  0.0392,  0.0367,  0.0620, -0.0167,  0.0363, -0.0246, -0.0424,\n",
      "          0.0371,  0.0273, -0.0222,  0.0413, -0.0354, -0.0840,  0.0584, -0.0236,\n",
      "          0.0054, -0.0012,  0.0409, -0.0326, -0.0022, -0.0167, -0.0454, -0.0147,\n",
      "         -0.0349, -0.0442,  0.0312, -0.0086,  0.0453, -0.0138,  0.0025,  0.0631,\n",
      "         -0.0671,  0.0421,  0.0063, -0.0843,  0.0177,  0.0732,  0.0159, -0.0231,\n",
      "         -0.0515,  0.0440, -0.0536, -0.0331, -0.0295, -0.0679, -0.0512, -0.0256,\n",
      "          0.0234,  0.0183,  0.0249, -0.0073, -0.0552,  0.0139, -0.0279, -0.0144,\n",
      "         -0.0054,  0.0314, -0.0146,  0.0777, -0.0165,  0.0015, -0.0607, -0.0138,\n",
      "         -0.0111, -0.0389,  0.0400,  0.0714,  0.0487, -0.0033, -0.0015, -0.0256,\n",
      "         -0.0829,  0.0759,  0.0511,  0.0767,  0.0522,  0.0385, -0.0087, -0.0464,\n",
      "         -0.0698, -0.0127, -0.0177,  0.0128,  0.0743, -0.0053,  0.0657, -0.0267,\n",
      "          0.0083,  0.0075, -0.0575, -0.0885,  0.0551, -0.0040,  0.0100,  0.0511,\n",
      "         -0.0434,  0.0718, -0.0230,  0.0542, -0.0376, -0.0107, -0.0500, -0.0023,\n",
      "         -0.0586, -0.0749, -0.0524, -0.0033, -0.0207,  0.0516,  0.0395,  0.0749,\n",
      "         -0.0223,  0.0312,  0.0667,  0.0237, -0.0924,  0.0415, -0.0817, -0.0249,\n",
      "          0.0481,  0.0645, -0.0042,  0.0633,  0.0564, -0.0694, -0.0242, -0.0329,\n",
      "          0.0357, -0.0660, -0.0419, -0.0307,  0.0359,  0.0435,  0.0489,  0.0175,\n",
      "          0.0198, -0.0842,  0.0124,  0.0140,  0.0572,  0.0193, -0.0244,  0.0295,\n",
      "          0.0162,  0.0468, -0.0745, -0.0052,  0.0395, -0.0471, -0.0519, -0.0360,\n",
      "          0.0488, -0.0138,  0.0847,  0.0151,  0.0106,  0.0226, -0.0888,  0.0291,\n",
      "         -0.0528,  0.0646,  0.0066, -0.0140, -0.0326, -0.0807, -0.0188, -0.0094,\n",
      "          0.0686, -0.0580,  0.0308,  0.0469,  0.0174,  0.0267, -0.0332, -0.0212,\n",
      "         -0.0463,  0.0324,  0.1524,  0.0298, -0.1022,  0.0075, -0.0030,  0.0114,\n",
      "          0.0247,  0.0411,  0.0110,  0.0684,  0.0545,  0.0085, -0.0022,  0.0333,\n",
      "         -0.0438,  0.0085, -0.0172, -0.0109, -0.0177, -0.0440,  0.0140, -0.0109,\n",
      "         -0.0322, -0.0060,  0.0018, -0.0089,  0.0034,  0.0224,  0.0335,  0.0275,\n",
      "         -0.0121, -0.0219, -0.0423,  0.0525,  0.0568,  0.0207,  0.0078,  0.0283,\n",
      "         -0.0425,  0.0466, -0.0449,  0.0119,  0.0217, -0.0015, -0.0684,  0.0596,\n",
      "         -0.0407,  0.0065,  0.0105, -0.0582, -0.0534, -0.0602,  0.0658, -0.0029,\n",
      "         -0.1081, -0.0097, -0.0123, -0.0181,  0.0384, -0.0245,  0.0873,  0.0507,\n",
      "         -0.0527, -0.0730,  0.0018,  0.0226,  0.0842, -0.0196,  0.0499,  0.0313,\n",
      "         -0.0331,  0.0887,  0.0697, -0.0540, -0.0105, -0.0077, -0.0116, -0.0079,\n",
      "          0.0485,  0.0148,  0.0286,  0.0307,  0.0384,  0.0125,  0.0094,  0.0740,\n",
      "          0.0563,  0.0161,  0.0091,  0.0252, -0.0046, -0.0120, -0.0650, -0.0053,\n",
      "          0.0392, -0.0468,  0.0242, -0.0069,  0.0581, -0.0330, -0.0337, -0.0828,\n",
      "          0.0317, -0.0039, -0.0588, -0.0100,  0.0053,  0.0040, -0.0512,  0.1042,\n",
      "         -0.0010,  0.0419, -0.0074, -0.0013, -0.0396, -0.0342, -0.0376,  0.0615,\n",
      "         -0.0269, -0.0346, -0.0011,  0.0631, -0.0363,  0.0172, -0.0490,  0.0146,\n",
      "          0.0170,  0.0559,  0.0513,  0.0636,  0.0032,  0.0506, -0.0616,  0.0203,\n",
      "         -0.0020,  0.0325,  0.0120, -0.0134, -0.1004, -0.0356, -0.1068,  0.0201,\n",
      "          0.0516,  0.0232,  0.0425,  0.0430, -0.0290,  0.0034, -0.0116, -0.0035,\n",
      "          0.0428, -0.0991, -0.0204,  0.0104,  0.0031,  0.0585,  0.0142, -0.0534,\n",
      "         -0.0004, -0.0503,  0.0444,  0.0063,  0.0286, -0.0252, -0.0375,  0.0274,\n",
      "          0.0355,  0.0237, -0.0099, -0.0685,  0.0135,  0.0286,  0.0175,  0.0603,\n",
      "          0.0415, -0.0249, -0.0060, -0.1141, -0.0137, -0.0443,  0.0255, -0.0834,\n",
      "         -0.0302,  0.0052, -0.0888,  0.0030, -0.0865,  0.0303,  0.0146, -0.0343,\n",
      "         -0.0937, -0.0051,  0.0166, -0.0166,  0.0394, -0.0138, -0.0029,  0.0630,\n",
      "         -0.0009,  0.0004, -0.0132,  0.0293, -0.0388, -0.0413, -0.0703, -0.0081,\n",
      "          0.0191, -0.0922, -0.0073, -0.0253, -0.0181, -0.0656, -0.0444, -0.1032,\n",
      "         -0.0280, -0.0195,  0.0721, -0.0057, -0.0183, -0.0214,  0.1157, -0.0343,\n",
      "         -0.0224,  0.0634, -0.0176, -0.0100, -0.0413, -0.0115, -0.0756, -0.0103,\n",
      "          0.0753,  0.0524,  0.0079,  0.0087, -0.0716,  0.0218, -0.0274,  0.0163,\n",
      "         -0.0383,  0.0344, -0.0230,  0.0080,  0.0642,  0.0250,  0.0279, -0.0454,\n",
      "         -0.0760, -0.0145,  0.0056, -0.0025,  0.0072,  0.0687,  0.0419, -0.0084,\n",
      "         -0.0473, -0.0582, -0.0016, -0.0500,  0.0009,  0.0554,  0.0811, -0.0610,\n",
      "          0.0325,  0.0443, -0.0679,  0.0632, -0.0339, -0.0295,  0.0250,  0.0546,\n",
      "          0.0260, -0.0202, -0.0414,  0.0698,  0.0287, -0.0343, -0.0052,  0.0493,\n",
      "          0.0160,  0.0117,  0.0463, -0.0036,  0.0440,  0.0506, -0.0876, -0.0797]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Class probabilities: tensor([[-5.0670,  3.3084, -0.0177,  ...,  1.5789,  1.8140, -1.0952]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 이미지 열기\n",
    "img = Image.open('/Users/ijimin/Downloads/siameseNet_graphVer (2)/Cat_face/Albert_Costa_0006.jpg')\n",
    "\n",
    "# Get cropped and prewhitened image tensor\n",
    "img_cropped = mtcnn(img)\n",
    "\n",
    "# Calculate embedding (unsqueeze to add batch dimension)\n",
    "if img_cropped is not None:\n",
    "    img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Embedding:\", img_embedding)\n",
    "\n",
    "    # Or, if using for VGGFace2 classification\n",
    "    resnet.classify = True\n",
    "    img_1 = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Class probabilities:\", img_1)\n",
    "else:\n",
    "    print(\"No face detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: tensor([[ 2.6877, -0.2690, -3.8392,  ...,  1.0535,  4.4194,  7.2202]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Class probabilities: tensor([[ 2.6877, -0.2690, -3.8392,  ...,  1.0535,  4.4194,  7.2202]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('/Users/ijimin/Downloads/siameseNet_graphVer (2)/Dog_v_face/WIN_20240312_16_17_40_Pro.jpg')\n",
    "\n",
    "# Get cropped and prewhitened image tensor\n",
    "img_cropped = mtcnn(img)\n",
    "\n",
    "# Calculate embedding (unsqueeze to add batch dimension)\n",
    "if img_cropped is not None:\n",
    "    img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Embedding:\", img_embedding)\n",
    "\n",
    "    # Or, if using for VGGFace2 classification\n",
    "    resnet.classify = True\n",
    "    img_2 = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Class probabilities:\", img_2)\n",
    "else:\n",
    "    print(\"No face detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in the image.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('/Users/ijimin/Downloads/IMG_4839.JPG')\n",
    "\n",
    "# Get cropped and prewhitened image tensor\n",
    "img_cropped = mtcnn(img)\n",
    "\n",
    "# Calculate embedding (unsqueeze to add batch dimension)\n",
    "if img_cropped is not None:\n",
    "    img_embedding = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Embedding:\", img_embedding)\n",
    "\n",
    "    # Or, if using for VGGFace2 classification\n",
    "    resnet.classify = True\n",
    "    img_3 = resnet(img_cropped.unsqueeze(0))\n",
    "    print(\"Class probabilities:\", img_3)\n",
    "else:\n",
    "    print(\"No face detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between embeddings: 557.9938354492188\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "distance = torch.dist(img_1, img_2)\n",
    "print(\"Distance between embeddings:\", distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between embeddings: 106.88618469238281\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "distance = torch.dist(img_3, img_2)\n",
    "print(\"Distance between embeddings:\", distance.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
